from django.http import JsonResponse, HttpResponseBadRequest
from django.shortcuts import render
from django.views.decorators.csrf import csrf_exempt
import base64
import io
from PIL import Image
import numpy as np
import os
import threading

try:
    import onnxruntime as ort
    print("âœ… ONNX Runtime baÅŸarÄ±yla yÃ¼klendi")
    print(f"ğŸ“¦ ONNX Runtime versiyonu: {ort.__version__}")
    providers = ort.get_available_providers()
    print(f"ğŸ”Œ Mevcut execution providers: {providers}")
    
    # CUDA provider kontrolÃ¼
    if 'CUDAExecutionProvider' in providers:
        print("ğŸš€ CUDA provider mevcut - GPU hÄ±zlandÄ±rmasÄ± kullanÄ±labilir!")
        # CUDA device bilgilerini al
        try:
            device_info = ort.get_device()
            print(f"ğŸ’» Aktif device: {device_info}")
        except:
            print("âš ï¸ Device bilgisi alÄ±namadÄ±")
    else:
        print("âš ï¸ CUDA provider bulunamadÄ± - sadece CPU kullanÄ±labilir")
        
    print("=" * 50)
except Exception as e:
    print(f"âŒ ONNX Runtime yÃ¼klenemedi: {e}")
    ort = None

# Basit Python tarafÄ± filtre/sÃ¼per Ã§Ã¶zÃ¼nÃ¼rlÃ¼k Ã¶rnekleri
# Not: GerÃ§ek SR iÃ§in onnxruntime ile bir model yÃ¼kleyebilirsiniz. Burada performans ve basitlik iÃ§in klasik iÅŸlemler var.

def index(request):
    return render(request, 'index.html')


def _np_from_base64(b64: str) -> np.ndarray:
    try:
        header, data = b64.split(',') if ',' in b64 else ('', b64)
        img_bytes = base64.b64decode(data)
        img = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        return np.array(img)
    except Exception:
        return None


def _to_base64_image(arr: np.ndarray) -> str:
    img = Image.fromarray(arr.astype(np.uint8), 'RGB')
    bio = io.BytesIO()
    img.save(bio, format='JPEG', quality=90)
    return 'data:image/jpeg;base64,' + base64.b64encode(bio.getvalue()).decode('utf-8')


def _resize(img: np.ndarray, scale: float) -> np.ndarray:
    """Optimize edilmiÅŸ resize fonksiyonu"""
    if abs(scale - 1.0) < 1e-3:
        return img
        
    pil = Image.fromarray(img)
    w, h = pil.size
    new_w, new_h = int(w*scale), int(h*scale)
    
    # KÃ¼Ã§Ã¼k gÃ¶rÃ¼ntÃ¼ler iÃ§in LANCZOS, bÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼ler iÃ§in BILINEAR (daha hÄ±zlÄ±)
    if w * h > 500000:  # 500k pixel Ã¼zeri
        resample = Image.BILINEAR
    else:
        resample = Image.LANCZOS
        
    pil = pil.resize((new_w, new_h), resample)
    return np.array(pil)

# Optimize edilmiÅŸ konvolÃ¼syon (scipy alternatifi)
def _apply_kernel(img: np.ndarray, kernel: np.ndarray, factor: float = 1.0, bias: float = 0.0) -> np.ndarray:
    """OpenCV kullanarak optimize edilmiÅŸ konvolÃ¼syon"""
    try:
        import cv2
        # OpenCV filter2D kullan (Ã§ok daha hÄ±zlÄ±)
        kernel_cv = kernel.astype(np.float32)
        
        # Her kanal iÃ§in ayrÄ± ayrÄ± iÅŸle
        result = np.zeros_like(img, dtype=np.float32)
        for c in range(img.shape[2]):
            result[:,:,c] = cv2.filter2D(img[:,:,c].astype(np.float32), -1, kernel_cv)
        
        result = result * factor + bias
        result = np.clip(result, 0, 255)
        return result.astype(np.uint8)
        
    except ImportError:
        print("âš ï¸ OpenCV bulunamadÄ±, yavaÅŸ NumPy konvolÃ¼syonu kullanÄ±lÄ±yor...")
        # Fallback to slow numpy implementation
        kh, kw = kernel.shape
        pad_h, pad_w = kh//2, kw//2
        
        # simetrik padding
        padded = np.pad(img, ((pad_h, pad_h),(pad_w, pad_w),(0,0)), mode='reflect')
        h, w, _ = img.shape
        out = np.zeros_like(img, dtype=np.float32)
        
        # Sadece merkez bÃ¶lgeyi iÅŸle (performans iÃ§in)
        step = max(1, min(h, w) // 200)  # BÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼lerde sampling
        
        for y in range(0, h, step):
            for x in range(0, w, step):
                ys, ye = y, min(y + step, h)
                xs, xe = x, min(x + step, w)
                
                for py in range(ys, ye):
                    for px in range(xs, xe):
                        region = padded[py:py+kh, px:px+kw, :]
                        out[py, px, 0] = np.sum(region[:,:,0] * kernel)
                        out[py, px, 1] = np.sum(region[:,:,1] * kernel)
                        out[py, px, 2] = np.sum(region[:,:,2] * kernel)
        
        out = out * factor + bias
        out = np.clip(out, 0, 255)
        return out.astype(np.uint8)

class ONNXUpscaler:
    _lock = threading.Lock()
    _session = None
    _providers = []
    _model_scale = 2  # FSRCNN x2 varsayÄ±lan

    @classmethod
    def _get_model_path(cls):
        models_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'static', 'models')
        os.makedirs(models_dir, exist_ok=True)
        model_path = os.path.join(models_dir, 'fsrcnn_x2.onnx')
        
        if not os.path.exists(model_path):
            print(f"ğŸ“¥ Model dosyasÄ± bulunamadÄ±, indiriliyor: {model_path}")
            try:
                import urllib.request
                # GerÃ§ek Ã§alÄ±ÅŸan FSRCNN model URL'si
                urls_to_try = [
                    'https://github.com/onnx/models/raw/main/vision/super_resolution/sub_pixel_cnn_2016/model/super-resolution-10.onnx',
                    'https://huggingface.co/rocca/super-resolution-onnx/resolve/main/fsrcnn-small.onnx'
                ]
                
                for url in urls_to_try:
                    try:
                        print(f"ğŸŒ Deneniyor: {url}")
                        urllib.request.urlretrieve(url, model_path)
                        print(f"âœ… Model baÅŸarÄ±yla indirildi!")
                        break
                    except Exception as e:
                        print(f"âŒ Bu URL baÅŸarÄ±sÄ±z: {e}")
                        continue
                        
                if not os.path.exists(model_path):
                    print("âš ï¸ Model indirilemedi, basit bir placeholder oluÅŸturuluyor...")
                    # Basit bir fallback - kÃ¼Ã§Ã¼k dummy model
                    return None
                    
            except Exception as e:
                print(f"âŒ Model indirme hatasÄ±: {e}")
                return None
                
        print(f"ğŸ“ Model dosyasÄ± hazÄ±r: {model_path}")
        return model_path

    @classmethod
    def session(cls):
        if ort is None:
            print("âŒ ONNX Runtime bulunamadÄ±, CUDA upscaling devre dÄ±ÅŸÄ±")
            return None, []
        with cls._lock:
            if cls._session is not None:
                print(f"â™»ï¸ Mevcut ONNX session kullanÄ±lÄ±yor (providers: {cls._providers})")
                return cls._session, cls._providers
            
            model_path = cls._get_model_path()
            if not model_path or not os.path.exists(model_path):
                print("âŒ ONNX model dosyasÄ± bulunamadÄ±")
                return None, []
            
            # Ã–ncelikli olarak CUDA, sonra CPU
            providers = []
            available_providers = ort.get_available_providers() if hasattr(ort, 'get_available_providers') else []
            print(f"ğŸ” Mevcut tÃ¼m providers: {available_providers}")
            
            if 'CUDAExecutionProvider' in available_providers:
                providers.append('CUDAExecutionProvider')
                print("âœ… CUDA provider eklendi")
            else:
                print("âš ï¸ CUDA provider bulunamadÄ±")
                
            providers.append('CPUExecutionProvider')
            print(f"ğŸ“‹ KullanÄ±lacak provider sÄ±rasÄ±: {providers}")
            
            sess_options = ort.SessionOptions()
            try:
                cls._session = ort.InferenceSession(model_path, providers=providers, sess_options=sess_options)
                cls._providers = cls._session.get_providers()
                print(f"ğŸ¯ ONNX session baÅŸarÄ±yla oluÅŸturuldu!")
                print(f"ğŸ”§ Aktif providers: {cls._providers}")
                return cls._session, cls._providers
            except Exception as e:
                print(f"âŒ ONNX session oluÅŸturulamadÄ±: {e}")
                return None, []

    @classmethod
    def upscale_x2(cls, img_rgb: np.ndarray) -> tuple[np.ndarray, list]:
        """Optimize edilmiÅŸ ONNX x2 upscaling"""
        print(f"ğŸ–¼ï¸ Upscale iÅŸlemi baÅŸlatÄ±lÄ±yor - gÃ¶rÃ¼ntÃ¼ boyutu: {img_rgb.shape}")
        
        # Ã‡ok bÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼leri Ã¶nce kÃ¼Ã§Ã¼lt (memory ve performans iÃ§in)
        original_shape = img_rgb.shape
        if original_shape[0] > 1080 or original_shape[1] > 1920:
            print("ğŸ“ GÃ¶rÃ¼ntÃ¼ Ã§ok bÃ¼yÃ¼k, Ã¶nce kÃ¼Ã§Ã¼ltÃ¼lÃ¼yor...")
            scale_down = min(1080/original_shape[0], 1920/original_shape[1])
            img_rgb = _resize(img_rgb, scale_down)
            print(f"ğŸ“ Yeni boyut: {img_rgb.shape}")
        
        session, providers = cls.session()
        if session is None:
            print("âŒ ONNX session bulunamadÄ±, CPU upscaling'e geÃ§iliyor")
            return None, providers
            
        print(f"ğŸš€ ONNX ile upscaling baÅŸlÄ±yor (providers: {providers})")
        
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ model iÃ§in hazÄ±rla
            img_float = img_rgb.astype(np.float32) / 255.0
            
            # Model input shape kontrolÃ¼
            input_shape = session.get_inputs()[0].shape
            print(f"ğŸ” Model beklenen input shape: {input_shape}")
            
            # EÄŸer model 1-channel (Y) bekliyorsa RGB'yi Y'ye Ã§evir
            if len(input_shape) == 4 and input_shape[1] == 1:
                # RGB to Y (luminance)
                img_y = np.dot(img_float, [0.299, 0.587, 0.114])
                chw = img_y[None, None, :, :]  # NCHW format
                print("ğŸ”„ RGB -> Y dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapÄ±ldÄ±")
            else:
                # RGB olarak bÄ±rak
                chw = np.transpose(img_float, (2,0,1))[None, ...]  # NCHW format
                print("ğŸ”„ RGB formatÄ± korundu")
            
            print(f"ğŸ“ Model girdi ÅŸekli: {chw.shape}")
            
            input_name = session.get_inputs()[0].name
            output_name = session.get_outputs()[0].name
            print(f"ğŸ”Œ Model girdi: {input_name}, Ã§Ä±ktÄ±: {output_name}")
            
            # ONNX inference
            out = session.run([output_name], {input_name: chw})[0]
            print(f"âœ… ONNX inference tamamlandÄ± - Ã§Ä±ktÄ± ÅŸekli: {out.shape}")
            
            # Output'u iÅŸle
            if out.shape[1] == 1:  # Y channel output
                # Y kanalÄ±nÄ± RGB'ye geri Ã§evir
                out_y = np.clip(out[0, 0] * 255.0, 0, 255).astype(np.uint8)
                # Basit grayscale to RGB
                out_rgb = np.stack([out_y, out_y, out_y], axis=2)
                print("ğŸ”„ Y -> RGB dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapÄ±ldÄ±")
            else:
                # RGB output
                out_rgb = np.clip(np.transpose(out[0], (1,2,0)) * 255.0, 0, 255).astype(np.uint8)
                print("ğŸ”„ RGB output iÅŸlendi")
            
            print(f"ğŸ¯ Final gÃ¶rÃ¼ntÃ¼ boyutu: {out_rgb.shape}")
            return out_rgb, providers
            
        except Exception as e:
            print(f"âŒ ONNX upscaling hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return None, providers


kernels = {
    'sharpenLite': (np.array([[0, -0.2, 0], [-0.2, 2, -0.2], [0, -0.2, 0]]), 1.0, 0.0),
    'sharpenStrong': (np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]), 1.0, 0.0),
    'edgeBoost': (np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]), 0.2, 0.0),
    'gaussianBlur3': (np.array([[1,2,1],[2,4,2],[1,2,1]])/16.0, 1.0, 0.0),
    'boxBlur3': (np.ones((3,3))/9.0, 1.0, 0.0),
}


def _process_numpy(img: np.ndarray, scale: float, mode: str, grayscale: bool = False, contrast: float = 1.0) -> np.ndarray:
    print(f"ğŸ¨ Ä°ÅŸlem baÅŸlÄ±yor - mod: {mode}, Ã¶lÃ§ek: {scale}, gri: {grayscale}, kontrast: {contrast}")
    
    # Performans kontrolÃ¼ - Ã§ok bÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼leri limitele
    h, w = img.shape[:2]
    is_large = (h * w) > 1000000  # 1M pixel Ã¼zeri
    if is_large:
        print(f"âš¡ BÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼ tespit edildi ({h}x{w}), hÄ±zlÄ± mod aktif")
    
    # EÄŸer ONNX SR seÃ§ildiyse Ã¶nce x2 SR uygula
    if mode == 'fsrcnn':
        print("ğŸ”¥ FSRCNN modu seÃ§ildi, ONNX upscaling deneniyor...")
        sr, providers = ONNXUpscaler.upscale_x2(img)
        if sr is not None:
            print("âœ… ONNX upscaling baÅŸarÄ±lÄ±!")
            out = sr
            # istenen Ã¶lÃ§ek 2 deÄŸilse ek yeniden Ã¶rnekleme uygula
            if abs(scale - 2.0) > 1e-3:
                print(f"ğŸ“ Ek Ã¶lÃ§ekleme uygulanÄ±yor: {scale / 2.0}")
                out = _resize(out, scale / 2.0)
        else:
            # GPU/Model yoksa klasik Ã¶lÃ§eklemeye dÃ¼ÅŸ
            print("âš ï¸ ONNX baÅŸarÄ±sÄ±z, klasik Ã¶lÃ§eklemeye geÃ§iliyor")
            out = _resize(img, scale)
    else:
        # Ã¶lÃ§ekle
        print(f"ğŸ“ Klasik Ã¶lÃ§ekleme uygulanÄ±yor: {scale}")
        out = _resize(img, scale)
    if grayscale:
        g = np.dot(out[...,:3], [0.299, 0.587, 0.114])
        out = np.stack([g, g, g], axis=2).astype(np.uint8)
    # Kontrast ayarÄ± (basit): (x - 128)*c + 128
    if contrast and abs(contrast - 1.0) > 1e-3:
        out = np.clip((out.astype(np.float32) - 128.0) * float(contrast) + 128.0, 0, 255).astype(np.uint8)

    # Filtre uygulama - bÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼lerde basitleÅŸtir
    if mode == 'lite':
        if not is_large:
            k, f, b = kernels['sharpenLite']
            out = _apply_kernel(out, k, f, b)
        else:
            print("âš¡ BÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼ - lite filtre atlandÄ±")
    elif mode == 'quality':
        k, f, b = kernels['edgeBoost']
        out = _apply_kernel(out, k, f, b)
        if not is_large:  # Sadece kÃ¼Ã§Ã¼k gÃ¶rÃ¼ntÃ¼lerde ikinci filtre
            k, f, b = kernels['sharpenStrong']
            out = _apply_kernel(out, k, f, b)
    elif mode == 'ultra':
        if not is_large:
            k, f, b = kernels['gaussianBlur3']
            out = _apply_kernel(out, k, f, b)
            k, f, b = kernels['edgeBoost']
            out = _apply_kernel(out, k, f, b)
            k, f, b = kernels['sharpenStrong']
            out = _apply_kernel(out, k, f, b)
        else:
            print("âš¡ BÃ¼yÃ¼k gÃ¶rÃ¼ntÃ¼ - ultra filtreler basitleÅŸtirildi")
            k, f, b = kernels['edgeBoost']
            out = _apply_kernel(out, k, f, b)
    elif mode == 'smooth':
        k, f, b = kernels['gaussianBlur3']
        out = _apply_kernel(out, k, f, b)
        if not is_large:
            k, f, b = kernels['sharpenLite']
            out = _apply_kernel(out, k, f, b)
    elif mode == 'denoise':
        k, f, b = kernels['boxBlur3']
        out = _apply_kernel(out, k, f, b)
        if not is_large:
            k, f, b = kernels['sharpenLite']
            out = _apply_kernel(out, k, f, b)
    else:
        k, f, b = kernels['edgeBoost']
        out = _apply_kernel(out, k, f, b)
        if not is_large:
            k, f, b = kernels['sharpenStrong']
            out = _apply_kernel(out, k, f, b)
    return out


@csrf_exempt
def process_frame(request):
    if request.method != 'POST':
        return HttpResponseBadRequest('POST bekleniyor')
    data = request.POST
    b64 = data.get('image')
    scale = float(data.get('scale', '2'))
    mode = data.get('model', 'quality')
    grayscale = data.get('grayscale', '0') == '1'
    contrast = float(data.get('contrast', '1.0'))
    npimg = _np_from_base64(b64)
    if npimg is None:
        return HttpResponseBadRequest('GeÃ§ersiz gÃ¶rÃ¼ntÃ¼')
    out = _process_numpy(npimg, scale, mode, grayscale=grayscale, contrast=contrast)
    b64_out = _to_base64_image(out)
    return JsonResponse({'image': b64_out})

@csrf_exempt
def info(request):
    providers = []
    active = []
    cuda_available = False
    gpu_info = {}
    
    print("ğŸ” Sistem bilgileri toplanÄ±yor...")
    
    if ort is not None:
        try:
            providers = getattr(ort, 'get_available_providers', lambda: [])()
            print(f"ğŸ“‹ TÃ¼m providers: {providers}")
            
            # CUDA provider kontrolÃ¼
            cuda_available = 'CUDAExecutionProvider' in providers
            print(f"ğŸš€ CUDA mevcut: {cuda_available}")
            
        except Exception as e:
            print(f"âŒ Provider bilgisi alÄ±namadÄ±: {e}")
            providers = []
            
        # Session bilgilerini al - basit ÅŸekilde
        try:
            sess, active = ONNXUpscaler.session()
            active = active or []
            print(f"ğŸ¯ Aktif providers: {active}")
        except Exception as e:
            print(f"âš ï¸ Session bilgisi alÄ±namadÄ±: {e}")
            active = []
    else:
        print("âŒ ONNX Runtime yÃ¼klÃ¼ deÄŸil")
    
    # GPU bilgilerini basit ÅŸekilde topla
    gpu_info = {'status': 'basic_info_only'}
    
    result = {
        'onnxruntime': ort is not None,
        'onnxruntime_version': getattr(ort, '__version__', 'unknown') if ort else None,
        'available_providers': providers,
        'active_providers': active,
        'cuda_available': cuda_available,
        'gpu_info': gpu_info
    }
    
    print(f"ğŸ“Š DÃ¶ndÃ¼rÃ¼len bilgiler: {result}")
    return JsonResponse(result)
